{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "TP6_synthese.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanisamrouche/data_science/blob/main/TP6_synthese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hHSPNzP2GPd"
      },
      "source": [
        "# Master Informatique AMU, ISD, exercice de synthèse (TP6)\n",
        "\n",
        "\n",
        "Voici un exercice vous permettant de synthétiser quelques unes de vos connaissances expérimentales en matière de classification à partir de données. Le code python doit être le plus concis possible.\n",
        "\n",
        "Etant donné le no-free-lunch theorem, nous vous confions la tâche de déterminer le meilleur modèle pour réaliser une tâche de régression transformée en tâche de classification, avec le test statistique qui garantit ce choix avec grande confiance.\n",
        "\n",
        "Remettre ce fichier ipynb complété. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3gNCyp12GPi"
      },
      "source": [
        "### Préparation des données\n",
        "Nous allons utiliser un jeu de données réel - tiré de *Tsanas & Xifara : Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools, Energy and Buildings, Vol. 49, pp. 560-567, 2012* - disponible sur Ametice (dataenergy.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HkFb1_y2GPk"
      },
      "source": [
        "Les 8 premières colonnes correspondent aux attributs descriptifs et les deux dernières, aux charges de chauffage et de climatisation (dans cet ordre).\n",
        "Pour les utiliser en Python, vous pourrez vous servir du code suivant :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x6-Ayvg2GPm"
      },
      "source": [
        "import numpy as np\n",
        "data = np.loadtxt(\"./dataenergy.csv\")\n",
        "X = data[:,:-2]\n",
        "Y = data[:,-2:]\n",
        "Yheat = Y[:,0]\n",
        "Ycool = Y[:,1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRZbBbHA2GPo"
      },
      "source": [
        "Le problème initial, tel que présenté ici, est un problème de régression multi-tâches. Nous allons le simplifier en le transformant en un problème de classification dont la classe sera le niveau de charge de chauffage : par une méthode de clustering, on veut répartir les charges de chauffage en 3 classes : faibles, moyennes, élevées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXKrTZ1v2GPq"
      },
      "source": [
        "A vous de jouer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY-RhBdv2GPr",
        "outputId": "d8313819-f21a-4315-f7d7-ca8eb4ff4e8f"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "# La suite ? il s'agit de définir un classifieur du k-means avec k=3 \n",
        "# et d'utiliser la méthode 'fit' sur lensemble des etiquettes de chauffage Yheat\n",
        "# Attention : les Y sont des vecteurs et les classifieurs sklearn ont besoin d'array :\n",
        "# il faut les reshaper : Yheat_vector = Yheat.reshape(-1,1)\n",
        "# Après apprentissage du kmeans, les classes des données utilisées sont stockées dans mon_classifieur.labels_\n",
        "Yheat_vector = Yheat.reshape(-1,1)\n",
        "kmeans = KMeans(n_clusters=3, random_state=0).fit(Yheat_vector)\n",
        "y = kmeans.labels_\n",
        "print(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0\n",
            " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0\n",
            " 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0 2 2 2 2\n",
            " 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
            " 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
            " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 0 0 0 2 0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 0 0 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBXXcYKy2GPs"
      },
      "source": [
        "### Apprentissage des modèles\n",
        "Nous voulons comparer deux méthodes de classification supervisée :\n",
        "1. Les k-plus proches voisins (*KNeighborsClassifier* de la classe *sklearn.neighbors*, hyperparamètre à régler : *n_neighbors*)\n",
        "2. Les arbres de décision  (*DecisionTreeClassifier* de la classe *sklearn.tree*, hyperparamètre à régler : *max_depth*)\n",
        "\n",
        "Ecrivez le code permettant de :\n",
        "1. Séparer les données en un échantillon d'apprentissage et un échantillon de test (60/40)\n",
        "2. Sélectionner les meilleurs valeurs des hyper-paramètres sur l'échantillon d'apprentissage par validation croisée en utilisant 10 folders (pour optimisation de l'erreur)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_I697As2GPu",
        "outputId": "c0bf39e8-4d97-4a4e-a434-35defbe9e560"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.40)\n",
        "dic_param = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15,20],'p':   [0.5, 1, 2, 5, 8, 12]}\n",
        "select_hppmt = GridSearchCV(KNeighborsClassifier(), dic_param, cv=10)\n",
        "select_hppmt.fit(X_train, y_train)\n",
        "print(select_hppmt.best_params_)\n",
        "#print(select_hppmt.cv_results_)\n",
        "# A vous"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 3, 'p': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "80 fits failed out of a total of 480.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
            "    return self._fit(X, y)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 437, in _fit\n",
            "    self._check_algorithm_metric()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 395, in _check_algorithm_metric\n",
            "    raise ValueError(\"p must be greater or equal to one for minkowski metric\")\n",
            "ValueError: p must be greater or equal to one for minkowski metric\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.91521739 0.91304348 0.91304348 0.91304348 0.91304348\n",
            "        nan 0.90652174 0.89565217 0.89565217 0.89565217 0.89565217\n",
            "        nan 0.87391304 0.86521739 0.86521739 0.86521739 0.86521739\n",
            "        nan 0.8826087  0.88695652 0.88695652 0.88695652 0.88695652\n",
            "        nan 0.89782609 0.87826087 0.87826087 0.87826087 0.87826087\n",
            "        nan 0.89347826 0.8826087  0.8826087  0.8826087  0.8826087\n",
            "        nan 0.88913043 0.87608696 0.87608696 0.87608696 0.87608696\n",
            "        nan 0.88913043 0.88695652 0.88695652 0.88695652 0.88695652]\n",
            "  category=UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxHILx8kdhrI",
        "outputId": "c748f02e-9d9d-4dc4-f9e0-be5b69aa4615"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.40)\n",
        "dic_param2 = {'criterion' : ['gini', 'entropy'],\n",
        "                    'max_depth' : [i for i in range(1,21)],\n",
        "                   'max_leaf_nodes' : [i for i in range(10,211,20)]}\n",
        "select_hppmt2 = GridSearchCV(DecisionTreeClassifier(), dic_param2, cv=10)\n",
        "select_hppmt2.fit(X_train, y_train)\n",
        "print(select_hppmt2.best_params_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'gini', 'max_depth': 7, 'max_leaf_nodes': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wRXauDJ2GPv"
      },
      "source": [
        "### Analyse des résultats\n",
        "Afficher sur une courbe les scores de chacun des algorithmes avec la meilleure valeur d'hyperparamètre possible sur l'échantillon de **test**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oM8woPj2GPw"
      },
      "source": [
        "# A vous"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr78-_hJ2GPx"
      },
      "source": [
        "Pour chacune des méthodes, pour chaque meilleur hyperparamètre, effectuer le test de McNemar sur l'échantillon test pour décider finalement quel est la meilleure solution pour la prédiction de la charge de chauffage, avec 95% de confiance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdCm7R1R2GPz"
      },
      "source": [
        "# A vous"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLuQMsb2GPz"
      },
      "source": [
        "### Remise du résultat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TVRNydF2GP0"
      },
      "source": [
        "Alors, quelle est la meilleure solution (algorithme et hyper-paramètres ) ? \n",
        "\n",
        "Et enfin, pour cette solution, quelle est le taux réel de bonne classification, estimé par validation croisée 10 folds ? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujc5Fdzq2GP0"
      },
      "source": [
        "# a vous"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}